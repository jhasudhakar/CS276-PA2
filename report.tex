\documentclass{article}

\usepackage{enumerate}
\usepackage{hyperref}
\usepackage{geometry}
\usepackage{parskip}

\geometry{letterpaper}

\begin{document}

\title{CS276 PA2 Report}

\author{
  Jiawei Yao\\
  \texttt{jwyao@stanford.edu}
  \and
  Wei Wei\\
  \texttt{wwei2@stanford.edu}
}

\maketitle

\section{System Design}

When designing the system, we put an emphasis on the following aspects:

\begin{itemize}
    \item \textbf{Modularity}: conform to good OOP practices; favor abstraction over implementation; reduce coupling among different components.
    \item \textbf{Flexibility}: it should be easy to add/remove implementation of a module without breaking other parts of the system.
    \item \textbf{Efficiency}: the system should be as performant as possible.
\end{itemize}

An example of modularity is we want to use \texttt{LanguageModel} as source of vocabulary/lexicon for \texttt{CandidateGenerator}, but we don't want to couple \texttt{CandidateGenerator} with the concrete \texttt{LanguageModel}. So we introduced an interface \texttt{Vocabulary} and let \texttt{LanguageModel} implement that interface.

Examples of flexibility include that we want to implement various smoothing techniques on language model, so we make \texttt{LanguageModel} an abstract base class and let subclasses to implement \texttt{bigramProbability}. With this change, we are able to add different smoothing techniques with few code.

The system is modularized into three parts:

\begin{enumerate}
    \item \textbf{Language Model}, used to compute the $P(Q)$ part of the noisy channel model.
    \item \textbf{Noisy Channel Model}, used to compute the $P(R|Q)$ part.
    \item \textbf{Candidate Generator}, used to generate possible candidates of $Q$ given $R$.
\end{enumerate}

Each part is documented in detail in the following sections, with design decisions addressing the above aspects.

\section{Language Model}

Smoothing...

\cite{chen-goodman-99}\cite{cs124-lm}

\section{Noisy Channel Model}

Edit\cite{jm-book}\cite{kernighan-1990}

\section{Candidate Genenration}

Viterbi...

\section{Parameter Tuning}

Graphs...

\section{Extra Credit}

Yes, please!

\begin{thebibliography}{9}

\bibitem{chen-goodman-99}
    Chen, Stanley F and Goodman, Joshua.
    \emph{An empirical study of smoothing techniques for language modeling}.
    Proceedings of the 34th annual meeting on Association for Computational Linguistics. Association for Computational Linguistics, 1996.

\bibitem{kernighan-1990}
    Kernighan, Mark D., Kenneth W. Church, and William A. Gale.
    \emph{A spelling correction program based on a noisy channel model}.
    Proceedings of the 13th conference on Computational linguistics-Volume 2. Association for Computational Linguistics, 1990.

\bibitem{jm-book}
    Jurafsky, Dan, and James H. Martin.
    \emph{Speech \& Language Processing}.
    Pearson Education India, 2000, pp. 163--168

\bibitem{cs124-lm}
    Jurafsky, Dan.
    \emph{Language Modeling}.
    2014, available at \url{http://www.stanford.edu/class/cs124/lec/languagemodeling.pdf}
\end{thebibliography}

\end{document}
